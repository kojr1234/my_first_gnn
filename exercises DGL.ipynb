{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7dfae1e-e410-43a7-9725-b34daea4b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef18f4c-6fd2-4de4-9e22-fc51b30b6209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c592e45-d3c7-4761-a2a1-466e436be29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd17f55-11a4-4250-8ad8-b084a05821b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "        # self.conv3 = GraphConv(10, num_classes)\n",
    "        # self.seq = nn.Linear(5, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        # h = F.relu(h)\n",
    "        # h = self.conv3(g, h)\n",
    "        # h = F.relu(h)\n",
    "        # h = self.seq(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184274b3-5c8f-4837-912a-0f9a3a050342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiofujii/opt/anaconda3/envs/toptal_project/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.946, val acc: 0.136 (best 0.136), test acc: 0.130 (best 0.130)\n",
      "In epoch 5, loss: 1.891, val acc: 0.510 (best 0.510), test acc: 0.501 (best 0.501)\n",
      "In epoch 10, loss: 1.810, val acc: 0.568 (best 0.574), test acc: 0.591 (best 0.585)\n",
      "In epoch 15, loss: 1.709, val acc: 0.572 (best 0.574), test acc: 0.595 (best 0.585)\n",
      "In epoch 20, loss: 1.586, val acc: 0.592 (best 0.592), test acc: 0.615 (best 0.615)\n",
      "In epoch 25, loss: 1.442, val acc: 0.662 (best 0.662), test acc: 0.663 (best 0.663)\n",
      "In epoch 30, loss: 1.285, val acc: 0.694 (best 0.694), test acc: 0.696 (best 0.696)\n",
      "In epoch 35, loss: 1.121, val acc: 0.720 (best 0.720), test acc: 0.718 (best 0.718)\n",
      "In epoch 40, loss: 0.959, val acc: 0.726 (best 0.726), test acc: 0.722 (best 0.722)\n",
      "In epoch 45, loss: 0.805, val acc: 0.744 (best 0.744), test acc: 0.733 (best 0.733)\n",
      "In epoch 50, loss: 0.666, val acc: 0.750 (best 0.752), test acc: 0.741 (best 0.742)\n",
      "In epoch 55, loss: 0.546, val acc: 0.754 (best 0.754), test acc: 0.747 (best 0.744)\n",
      "In epoch 60, loss: 0.445, val acc: 0.762 (best 0.762), test acc: 0.747 (best 0.747)\n",
      "In epoch 65, loss: 0.361, val acc: 0.764 (best 0.764), test acc: 0.752 (best 0.748)\n",
      "In epoch 70, loss: 0.294, val acc: 0.760 (best 0.764), test acc: 0.759 (best 0.748)\n",
      "In epoch 75, loss: 0.241, val acc: 0.766 (best 0.766), test acc: 0.761 (best 0.761)\n",
      "In epoch 80, loss: 0.198, val acc: 0.768 (best 0.770), test acc: 0.766 (best 0.764)\n",
      "In epoch 85, loss: 0.164, val acc: 0.768 (best 0.770), test acc: 0.763 (best 0.764)\n",
      "In epoch 90, loss: 0.138, val acc: 0.770 (best 0.772), test acc: 0.766 (best 0.764)\n",
      "In epoch 95, loss: 0.117, val acc: 0.766 (best 0.772), test acc: 0.766 (best 0.764)\n"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6ee128-ff2a-49f5-aada-b40742e83c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307343c7-8e07-4c9c-a570-511e07536079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# star shepd graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72f3cb5-5c91-468c-a27e-f4076596ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d25b8c-6fc9-4570-8d18-7e3ff0c5c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalently, PyTorch LongTensors also work.\n",
    "g = dgl.graph((torch.LongTensor([0, 0, 0, 0, 0]), torch.LongTensor([1, 2, 3, 4, 5])), num_nodes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ae781a-4247-4d94-a742-39733bef3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can omit the number of nodes argument if you can tell the number of nodes from the edge list alone.\n",
    "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca482ed7-3d8b-4f71-8c52-e813d800e551",
   "metadata": {},
   "source": [
    "# assigning features to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d05c6a-c30c-476e-9e09-dcda5595e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning 3d node feature vector for each node\n",
    "g.ndata['x'] = torch.randn(6,3)\n",
    "\n",
    "# assigning 4d edge feature vector for each edge\n",
    "g.edata['a'] = torch.randn(5,4)\n",
    "\n",
    "# assigning 5x4 node feature matrix for each node. DGL supports multi-dimensional features\n",
    "g.ndata['y'] = torch.randn(6,5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56395558-a005-458a-a901-f95ed16d2531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1922,  1.7157, -0.7712],\n",
      "        [ 0.2557,  1.8470, -1.5688],\n",
      "        [ 0.8149, -1.0861,  1.2249],\n",
      "        [-1.0675,  0.4671, -0.3582],\n",
      "        [-0.5609,  0.0621, -0.3328],\n",
      "        [ 1.1135,  0.8310,  0.4783]])\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e98409-f3e9-48d2-9c6d-777cc8c19bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.1740e-01, -1.1059e+00,  9.4387e-01, -1.0236e+00],\n",
      "         [ 1.1906e-01,  8.8992e-01, -1.1529e+00,  7.6569e-01],\n",
      "         [-1.2758e+00,  6.8034e-02, -2.0166e+00, -2.9958e-01],\n",
      "         [ 6.3827e-01,  1.1994e+00,  4.6846e-01,  7.0318e-01],\n",
      "         [-5.8710e-02,  2.5240e-01,  4.6506e-01,  1.3793e-01]],\n",
      "\n",
      "        [[-8.8068e-02,  1.9922e+00,  6.5358e-01,  8.9653e-01],\n",
      "         [-1.1256e+00, -7.6091e-01, -2.1759e+00, -2.3135e+00],\n",
      "         [ 6.7946e-01, -5.2826e-01,  7.4475e-01, -9.7166e-01],\n",
      "         [ 4.0705e-01, -5.7047e-01,  3.6864e-01, -5.5453e-01],\n",
      "         [ 1.7703e-01,  5.4992e-01, -3.1467e-01,  1.3404e+00]],\n",
      "\n",
      "        [[ 1.2805e+00,  1.0879e+00, -1.0830e+00, -1.8653e+00],\n",
      "         [-6.6984e-01, -7.2599e-01,  5.6298e-02,  1.5494e-01],\n",
      "         [-2.8336e-01,  2.4520e-01,  9.0225e-01, -7.2946e-01],\n",
      "         [ 1.8777e-01, -1.6443e-01,  1.7212e-01,  1.0218e-01],\n",
      "         [-1.7572e+00,  2.9157e-01, -3.0790e-01, -1.0068e+00]],\n",
      "\n",
      "        [[ 1.1311e-01, -7.3879e-01, -1.6125e+00,  9.8744e-01],\n",
      "         [ 1.6376e-01, -1.6192e+00, -6.7076e-01, -5.7997e-01],\n",
      "         [ 1.6943e-03, -6.1730e-01, -1.0794e+00,  1.7375e-01],\n",
      "         [ 6.0237e-01,  1.0906e+00,  4.2878e-02, -2.3194e+00],\n",
      "         [-1.0389e+00,  1.6740e-02,  1.2342e+00, -5.5847e-01]],\n",
      "\n",
      "        [[ 2.4480e-01, -1.7043e+00, -5.3045e-01,  1.4876e+00],\n",
      "         [ 1.5271e+00, -1.0480e+00, -1.1199e+00, -2.6061e-01],\n",
      "         [ 2.8923e-01, -3.5583e-01, -4.2504e-01,  1.1392e+00],\n",
      "         [ 3.6674e-01, -4.9779e-01,  9.5488e-01, -1.3607e+00],\n",
      "         [ 1.5342e+00, -7.5937e-01, -1.2623e-01, -1.4668e+00]],\n",
      "\n",
      "        [[ 2.9793e-01, -6.4850e-03,  1.1656e-01,  1.4735e-01],\n",
      "         [-2.0457e-01,  9.3550e-01,  1.6953e-01, -5.9127e-01],\n",
      "         [ 1.1910e+00,  2.7345e+00,  2.5894e-01, -6.1232e-01],\n",
      "         [ 1.0025e+00,  4.9409e-01,  1.8273e-01,  2.6583e-01],\n",
      "         [-4.8156e-01, -3.8576e-01,  1.4072e+00, -1.5208e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de52838-2788-4994-86b9-6135370a7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7856,  1.0833, -1.3352,  1.0333],\n",
      "        [ 0.6354,  0.7014,  2.0382, -0.4109],\n",
      "        [-0.8996, -0.1350, -0.2898,  0.4645],\n",
      "        [-1.6151, -0.0227,  0.4396,  0.0025],\n",
      "        [-0.2631,  0.3728,  0.7462, -1.1694]])\n"
     ]
    }
   ],
   "source": [
    "print(g.edata['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50c14e4-9a47-445c-a5c4-973d39b89627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(g.num_nodes())\n",
    "print(g.num_edges())\n",
    "# Out degrees of the center node\n",
    "print(g.out_degrees(0))\n",
    "# In degrees of the center node - note that the graph is directed so the in degree should be 0.\n",
    "print(g.in_degrees(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c656912-b5b5-4c0b-9b20-4d851c5c8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg1 = g.subgraph([0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa4e8e2-ca14-47f9-a04e-907fd90fabe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-0.1922,  1.7157, -0.7712],\n",
       "        [ 0.2557,  1.8470, -1.5688],\n",
       "        [-1.0675,  0.4671, -0.3582]]), 'y': tensor([[[ 5.1740e-01, -1.1059e+00,  9.4387e-01, -1.0236e+00],\n",
       "         [ 1.1906e-01,  8.8992e-01, -1.1529e+00,  7.6569e-01],\n",
       "         [-1.2758e+00,  6.8034e-02, -2.0166e+00, -2.9958e-01],\n",
       "         [ 6.3827e-01,  1.1994e+00,  4.6846e-01,  7.0318e-01],\n",
       "         [-5.8710e-02,  2.5240e-01,  4.6506e-01,  1.3793e-01]],\n",
       "\n",
       "        [[-8.8068e-02,  1.9922e+00,  6.5358e-01,  8.9653e-01],\n",
       "         [-1.1256e+00, -7.6091e-01, -2.1759e+00, -2.3135e+00],\n",
       "         [ 6.7946e-01, -5.2826e-01,  7.4475e-01, -9.7166e-01],\n",
       "         [ 4.0705e-01, -5.7047e-01,  3.6864e-01, -5.5453e-01],\n",
       "         [ 1.7703e-01,  5.4992e-01, -3.1467e-01,  1.3404e+00]],\n",
       "\n",
       "        [[ 1.1311e-01, -7.3879e-01, -1.6125e+00,  9.8744e-01],\n",
       "         [ 1.6376e-01, -1.6192e+00, -6.7076e-01, -5.7997e-01],\n",
       "         [ 1.6943e-03, -6.1730e-01, -1.0794e+00,  1.7375e-01],\n",
       "         [ 6.0237e-01,  1.0906e+00,  4.2878e-02, -2.3194e+00],\n",
       "         [-1.0389e+00,  1.6740e-02,  1.2342e+00, -5.5847e-01]]]), '_ID': tensor([0, 1, 3])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg1.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a8a9ee-9597-42ae-9393-53f728cf8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg2 = g.edge_subgraph([0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8ac51b-17d7-4989-bfb6-c5fd84d717f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-0.1922,  1.7157, -0.7712],\n",
       "        [ 0.2557,  1.8470, -1.5688],\n",
       "        [ 0.8149, -1.0861,  1.2249],\n",
       "        [-0.5609,  0.0621, -0.3328]]), 'y': tensor([[[ 0.5174, -1.1059,  0.9439, -1.0236],\n",
       "         [ 0.1191,  0.8899, -1.1529,  0.7657],\n",
       "         [-1.2758,  0.0680, -2.0166, -0.2996],\n",
       "         [ 0.6383,  1.1994,  0.4685,  0.7032],\n",
       "         [-0.0587,  0.2524,  0.4651,  0.1379]],\n",
       "\n",
       "        [[-0.0881,  1.9922,  0.6536,  0.8965],\n",
       "         [-1.1256, -0.7609, -2.1759, -2.3135],\n",
       "         [ 0.6795, -0.5283,  0.7447, -0.9717],\n",
       "         [ 0.4070, -0.5705,  0.3686, -0.5545],\n",
       "         [ 0.1770,  0.5499, -0.3147,  1.3404]],\n",
       "\n",
       "        [[ 1.2805,  1.0879, -1.0830, -1.8653],\n",
       "         [-0.6698, -0.7260,  0.0563,  0.1549],\n",
       "         [-0.2834,  0.2452,  0.9023, -0.7295],\n",
       "         [ 0.1878, -0.1644,  0.1721,  0.1022],\n",
       "         [-1.7572,  0.2916, -0.3079, -1.0068]],\n",
       "\n",
       "        [[ 0.2448, -1.7043, -0.5305,  1.4876],\n",
       "         [ 1.5271, -1.0480, -1.1199, -0.2606],\n",
       "         [ 0.2892, -0.3558, -0.4250,  1.1392],\n",
       "         [ 0.3667, -0.4978,  0.9549, -1.3607],\n",
       "         [ 1.5342, -0.7594, -0.1262, -1.4668]]]), '_ID': tensor([0, 1, 2, 4])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)\n",
    "# edghe subgraph uses the edge index (not related to the node number)\n",
    "# that menas, when we use edge_subgraph([0,1,3]), we are specifying that we want\n",
    "# the subgraph that conains the edges 0 (connects 0 to 1), 1 (connects 0 to 2), and 3 (connects 0 to 4)\n",
    "sg2.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e00499fa-31c4-43ec-85af-4d13a8b823d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 3])\n",
      "tensor([0, 2])\n",
      "tensor([0, 1, 2, 4])\n",
      "tensor([0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# The original IDs of each node in sg1\n",
    "print(sg1.ndata[dgl.NID])\n",
    "# The original IDs of each edge in sg1\n",
    "print(sg1.edata[dgl.EID])\n",
    "# The original IDs of each node in sg2\n",
    "print(sg2.ndata[dgl.NID])\n",
    "# The original IDs of each edge in sg2\n",
    "print(sg2.edata[dgl.EID])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e666bbb-9eec-4a66-9618-7ebb1b9a7fa5",
   "metadata": {},
   "source": [
    "# transforming unidirectiona graph to bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3802e65d-6a5e-4e39-ace7-2f1c1a7d778a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 1, 2, 3, 4, 5]),\n",
       " tensor([1, 2, 3, 4, 5, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newg = dgl.add_reverse_edges(g)\n",
    "newg.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7aafa2-199c-4367-ba15-fefd4173af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we transform the edge information, we lose all features created for \n",
    "# the source graph\n",
    "newg.edata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6afd96-fddb-4f99-96f0-4d3abf9ff287",
   "metadata": {},
   "source": [
    "# save/load graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f35c10e-e0a1-4de2-9a87-069c6247619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6, num_edges=5,\n",
      "      ndata_schemes={'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
      "Graph(num_nodes=6, num_edges=5,\n",
      "      ndata_schemes={'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
      "Graph(num_nodes=3, num_edges=2,\n",
      "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
      "Graph(num_nodes=4, num_edges=3,\n",
      "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'a': Scheme(shape=(4,), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "dgl.save_graphs('graph.dgl', g)\n",
    "dgl.save_graphs('graphs.dgl', [g, sg1, sg2])\n",
    "\n",
    "# Load graphs\n",
    "(g,), _ = dgl.load_graphs('graph.dgl')\n",
    "print(g)\n",
    "(g, sg1, sg2), _ = dgl.load_graphs('graphs.dgl')\n",
    "print(g)\n",
    "print(sg1)\n",
    "print(sg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b646ec5-fd60-4d2e-8e3b-08663ac2f200",
   "metadata": {},
   "source": [
    "# Graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f60642cc-66af-490a-bd73-027aef41fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
    "dataset = dgl.data.GINDataset('PROTEINS', self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c88e887-1082-4df4-ac96-817284cb904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature dimensionality: 3\n",
      "Number of graph categories: 2\n"
     ]
    }
   ],
   "source": [
    "print('Node feature dimensionality:', dataset.dim_nfeats)\n",
    "print('Number of graph categories:', dataset.gclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd3bfbb-7828-450f-972b-dd2778b02895",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e5cd879-9ce3-4199-98f8-d2ee82f45e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dt in enumerate(dataset):\n",
    "    t[i] = dt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4679fdd0-0602-4bd9-9f75-34c4d31aac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the protein dataset is exatcly the format I want for sites\n",
    "# dataset contains 1113 graphs, each of them have the tensor specifying the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcbd5b2e-30be-4d02-83ae-a9be677d8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4893c30-7813-4e60-b9a9-6ffaa7a94fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attr': tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abc9879f-745e-4365-99da-6d2d06c2bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28e94ae7-a885-41fc-bf93-8a808c7f5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c85f80b-fd26-42e7-a3d6-78200e9bc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f8d8188-6ce5-4e0c-b222-a035dedb4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc55fc95-e52e-4d7d-a2d5-41a78689fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6dd4cc5-ab63-4b51-a06c-edd8feb6a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph(num_nodes=764, num_edges=3388,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), tensor([0, 0, 0, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "batch = next(it)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a21a4953-b1dc-4e98-b0bd-5b16c21cd04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,  ..., 763, 763, 763]),\n",
       " tensor([  1,  71,   0,  ..., 761, 762, 763]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].all_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf185a5-4400-41c2-9b0f-ee88e839fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first element is the batched graph. This single elemtn contains all (in this case 5) graphs\n",
    "# that we want to consider in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f666c5d-19df-4e24-9bb1-18409e47375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes for each graph element in the batch: tensor([620,  69,  54,  13,   8])\n",
      "Number of edges for each graph element in the batch: tensor([2718,  319,  252,   63,   36])\n"
     ]
    }
   ],
   "source": [
    "batched_graph, labels = batch\n",
    "print('Number of nodes for each graph element in the batch:', batched_graph.batch_num_nodes())\n",
    "print('Number of edges for each graph element in the batch:', batched_graph.batch_num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d6349d-6a6e-442e-9594-15befc334d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original graphs in the minibatch:\n",
      "[Graph(num_nodes=620, num_edges=2718,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=69, num_edges=319,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=54, num_edges=252,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=13, num_edges=63,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=8, num_edges=36,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})]\n"
     ]
    }
   ],
   "source": [
    "# Recover the original graph elements from the minibatch\n",
    "graphs = dgl.unbatch(batched_graph)\n",
    "print('The original graphs in the minibatch:')\n",
    "print(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d923f575-52c4-4f94-82b8-03cfdf445333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, h_feats)\n",
    "        self.conv3 = GraphConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bdb9640-ca45-4c62-ac1d-c67a25f2b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2914798206278027\n"
     ]
    }
   ],
   "source": [
    "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6a74926-1438-493d-8255-89ad9ad7b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dgl.data import GINDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling\n",
    "import argparse\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP    \n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "    \n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        num_layers = 5\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "        for layer in range(num_layers - 1): # excluding the input layer\n",
    "            if layer == 0:\n",
    "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.ginlayers.append(GINConv(mlp, learn_eps=False)) # set to True if learning epsilon\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.pool = SumPooling() # change to mean readout (AvgPooling) on social network datasets\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = 0\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
    "        return score_over_layer\n",
    "    \n",
    "def split_fold10(labels, fold_idx=0):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    idx_list = []\n",
    "    for idx in skf.split(np.zeros(len(labels)), labels):\n",
    "        idx_list.append(idx)\n",
    "    train_idx, valid_idx = idx_list[fold_idx]\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "def evaluate(dataloader, device, model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "    for batched_graph, labels in dataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        feat = batched_graph.ndata.pop('attr')\n",
    "        total += len(labels)\n",
    "        logits = model(batched_graph, feat)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "    acc = 1.0 * total_correct / total\n",
    "    return acc\n",
    "\n",
    "def train(train_loader, val_loader, device, model):\n",
    "    # loss function, optimizer and scheduler\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    \n",
    "    # training loop    \n",
    "    for epoch in range(400):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch, (batched_graph, labels) in enumerate(train_loader):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feat = batched_graph.ndata.pop('attr')\n",
    "            logits = model(batched_graph, feat)\n",
    "            loss = loss_fcn(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        train_acc = evaluate(train_loader, device, model)\n",
    "        valid_acc = evaluate(val_loader, device, model)\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f} \"\n",
    "              . format(epoch, total_loss / (batch + 1), train_acc, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df793f6e-8516-424a-aad8-1640884b0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [l for _, l in dataset]\n",
    "train_idx, val_idx = split_fold10(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2eb431a-3229-48c2-a4b4-aa2858ec470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = GraphDataLoader(dataset, sampler=SubsetRandomSampler(train_idx),\n",
    "                               batch_size=128, pin_memory=torch.cuda.is_available())\n",
    "val_loader = GraphDataLoader(dataset, sampler=SubsetRandomSampler(val_idx),\n",
    "                             batch_size=128, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1675c362-3183-4f13-bbf6-a7e7310e2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GIN model\n",
    "in_size = dataset.dim_nfeats\n",
    "out_size = dataset.gclasses\n",
    "model = GIN(in_size, 16, out_size).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e4de880-62ba-4fa0-acd1-0ab0cf80a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_dataloader, test_dataloader, 'cpu', model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
